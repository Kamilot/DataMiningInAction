{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR Conv Net\n",
    "\n",
    "И так, в этом ноутбуке Вы сделаете превую в своей жизни сверточную сеть! На сложном датасете. Скачайте его кстати, \n",
    "\n",
    "```(bash)\n",
    "mkdir cifar10\n",
    "curl -o cifar-10-python.tar.gz https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "tar -xvzf cifar-10-python.tar.gz -C cifar10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  162M  100  162M    0     0  2408k      0  0:01:09  0:01:09 --:--:-- 2787k\n",
      "cifar-10-batches-py/\n",
      "cifar-10-batches-py/data_batch_4\n",
      "cifar-10-batches-py/readme.html\n",
      "cifar-10-batches-py/test_batch\n",
      "cifar-10-batches-py/data_batch_3\n",
      "cifar-10-batches-py/batches.meta\n",
      "cifar-10-batches-py/data_batch_2\n",
      "cifar-10-batches-py/data_batch_5\n",
      "cifar-10-batches-py/data_batch_1\n"
     ]
    }
   ],
   "source": [
    "!mkdir cifar10\n",
    "!curl -o cifar-10-python.tar.gz https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "!tar -xvzf cifar-10-python.tar.gz -C cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cifar import load_CIFAR10\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) \n",
    "\n",
    "cifar10_dir = './cifar10/cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3, 32, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.rollaxis(X_train, 3, 1).astype(np.float32)\n",
    "X_test = np.rollaxis(X_test, 3, 1).astype(np.float32)\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = np.random.permutation(len(X_train))\n",
    "old_X_train = np.copy(X_train)\n",
    "old_y_train = np.copy(y_train)\n",
    "X_train = np.array([old_X_train[index] for index in indices])\n",
    "y_train = np.array([old_y_train[index] for index in indices])\n",
    "del old_X_train\n",
    "del old_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_val = X_train[-1000:]\n",
    "y_val = y_train[-1000:]\n",
    "X_train = X_train[:-1000]\n",
    "y_train = y_train[:-1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import lasagne\n",
    "from theano import tensor as T\n",
    "from lasagne.nonlinearities import *\n",
    "\n",
    "input_X = T.tensor4(\"X\")\n",
    "target_y = T.vector(\"target Y integer\",dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так задаётся архитектура нейронки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_layer = lasagne.layers.InputLayer(shape=(None,3, 32, 32), input_var=input_X)\n",
    "#input_layer = lasagne.layers.InputLayer(shape = input_shape,input_var=input_X)\n",
    "\n",
    "\n",
    "conv11 = lasagne.layers.Conv2DLayer(input_layer, num_filters=32, filter_size=(3, 3),\n",
    "                                   nonlinearity=lasagne.nonlinearities.rectify, pad=\"same\",\n",
    "                                   W=lasagne.init.GlorotNormal(), b=lasagne.init.Constant(0.1),\n",
    "                                   name=\"conv11\")\n",
    "\n",
    "conv12 = lasagne.layers.Conv2DLayer(conv11, num_filters=32, filter_size=(3, 3),\n",
    "                                   nonlinearity=lasagne.nonlinearities.rectify, pad=\"same\",\n",
    "                                   W=lasagne.init.GlorotNormal(), b=lasagne.init.Constant(0.1),\n",
    "                                   name=\"conv12\")\n",
    "\n",
    "pool1 = lasagne.layers.MaxPool2DLayer(conv12, pool_size=(2, 2), name=\"pool1\")\n",
    "\n",
    "conv21 = lasagne.layers.Conv2DLayer(pool1, num_filters=64, filter_size=(3, 3),\n",
    "                                   nonlinearity=lasagne.nonlinearities.rectify, pad=\"same\",\n",
    "                                   W=lasagne.init.GlorotNormal(), b=lasagne.init.Constant(0.1),\n",
    "                                   name=\"conv21\")\n",
    "\n",
    "conv22 = lasagne.layers.Conv2DLayer(conv21, num_filters=64, filter_size=(3, 3),\n",
    "                                   nonlinearity=lasagne.nonlinearities.rectify, pad=\"same\",\n",
    "                                   W=lasagne.init.GlorotNormal(), b=lasagne.init.Constant(0.1),\n",
    "                                   name=\"conv22\")\n",
    "\n",
    "pool2 = lasagne.layers.MaxPool2DLayer(conv22, pool_size=(2, 2), name=\"pool2\")\n",
    "\n",
    "conv31 = lasagne.layers.Conv2DLayer(lasagne.layers.dropout(pool2, p=.25), num_filters=128, filter_size=(3, 3),\n",
    "                                   nonlinearity=lasagne.nonlinearities.rectify, pad=\"same\",\n",
    "                                   W=lasagne.init.GlorotNormal(), b=lasagne.init.Constant(0.1),\n",
    "                                   name=\"conv31\")\n",
    "\n",
    "conv32 = lasagne.layers.Conv2DLayer(conv31, num_filters=128, filter_size=(3, 3),\n",
    "                                   nonlinearity=lasagne.nonlinearities.rectify, pad=\"same\",\n",
    "                                   W=lasagne.init.GlorotNormal(), b=lasagne.init.Constant(0.1),\n",
    "                                   name=\"conv32\")\n",
    "\n",
    "pool3 = lasagne.layers.MaxPool2DLayer(conv32, pool_size=(2, 2), name=\"pool3\")\n",
    "\n",
    "fc1 = lasagne.layers.DenseLayer(lasagne.layers.dropout(pool3, p=.5),\n",
    "                                num_units=2048,\n",
    "                                nonlinearity=lasagne.nonlinearities.rectify,\n",
    "                                W=lasagne.init.GlorotNormal(),\n",
    "                                b=lasagne.init.Constant(0.1),\n",
    "                                name=\"fc1\")\n",
    "\n",
    "# fc2 = lasagne.layers.DenseLayer(lasagne.layers.dropout(fc1, p=.5),\n",
    "#                                 num_units=2048,\n",
    "#                                 nonlinearity=lasagne.nonlinearities.rectify,\n",
    "#                                 W=lasagne.init.Normal(std=0.1),\n",
    "#                                 name=\"fc2\")\n",
    "\n",
    "dense_output = lasagne.layers.DenseLayer(lasagne.layers.dropout(fc1, p=.4),\n",
    "                                         num_units=10,\n",
    "                                         nonlinearity=lasagne.nonlinearities.softmax, \n",
    "                                         W=lasagne.init.GlorotNormal(),\n",
    "                                         b=lasagne.init.Constant(0.1),\n",
    "                                         name=\"output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#предсказание нейронки (theano-преобразование)\n",
    "y_predicted_train = lasagne.layers.get_output(dense_output, deterministic=False)\n",
    "y_predicted = lasagne.layers.get_output(dense_output, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[conv11.W, conv11.b, conv12.W, conv12.b, conv21.W, conv21.b, conv22.W, conv22.b, conv31.W, conv31.b, conv32.W, conv32.b, fc1.W, fc1.b, output.W, output.b]\n"
     ]
    }
   ],
   "source": [
    "#все веса нейронки (shared-переменные)\n",
    "all_weights = lasagne.layers.get_all_params(dense_output)\n",
    "print(all_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### дальше вы могли бы просто\n",
    "* задать функцию ошибки вручную\n",
    "* посчитать градиент ошибки по all_weights\n",
    "* написать updates\n",
    "* но это долго, а простой шаг по градиенту - не самый лучший смособ оптимизировать веса\n",
    "\n",
    "Вместо этого, опять используем lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#функция ошибки - средняя кроссэнтропия\n",
    "loss_train = lasagne.objectives.categorical_crossentropy(y_predicted_train,target_y).mean()\n",
    "loss = lasagne.objectives.categorical_crossentropy(y_predicted,target_y).mean()\n",
    "\n",
    "#<возможно добавить регуляризатор>\n",
    "\n",
    "accuracy_train = lasagne.objectives.categorical_accuracy(y_predicted_train,target_y).mean()\n",
    "accuracy = lasagne.objectives.categorical_accuracy(y_predicted,target_y).mean()\n",
    "\n",
    "#сразу посчитать словарь обновлённых значений с шагом по градиенту, как раньше\n",
    "updates_sgd = lasagne.updates.adam(loss_train, all_weights,learning_rate=0.0001)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#функция, которая обучает сеть на 1 шаг и возвращащет значение функции потерь и точности\n",
    "train_fun = theano.function([input_X,target_y],[loss_train,accuracy_train],updates= updates_sgd)\n",
    "\n",
    "#функция, которая считает точность\n",
    "accuracy_fun = theano.function([input_X,target_y],accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вот и всё, пошли её учить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Процесс обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 60 took 23.610s\n",
      "  training loss (in-iteration):\t\t2.027393\n",
      "  train accuracy:\t\t31.86 %\n",
      "  validation accuracy:\t\t43.60 %\n",
      "Epoch 2 of 60 took 24.152s\n",
      "  training loss (in-iteration):\t\t1.475434\n",
      "  train accuracy:\t\t45.88 %\n",
      "  validation accuracy:\t\t52.40 %\n",
      "Epoch 3 of 60 took 23.735s\n",
      "  training loss (in-iteration):\t\t1.309313\n",
      "  train accuracy:\t\t52.69 %\n",
      "  validation accuracy:\t\t55.60 %\n",
      "Epoch 4 of 60 took 23.902s\n",
      "  training loss (in-iteration):\t\t1.198210\n",
      "  train accuracy:\t\t56.86 %\n",
      "  validation accuracy:\t\t60.00 %\n",
      "Epoch 5 of 60 took 24.681s\n",
      "  training loss (in-iteration):\t\t1.107837\n",
      "  train accuracy:\t\t60.71 %\n",
      "  validation accuracy:\t\t62.40 %\n",
      "Epoch 6 of 60 took 25.036s\n",
      "  training loss (in-iteration):\t\t1.028142\n",
      "  train accuracy:\t\t63.38 %\n",
      "  validation accuracy:\t\t65.50 %\n",
      "Epoch 7 of 60 took 24.959s\n",
      "  training loss (in-iteration):\t\t0.959247\n",
      "  train accuracy:\t\t65.97 %\n",
      "  validation accuracy:\t\t65.10 %\n",
      "Epoch 8 of 60 took 25.334s\n",
      "  training loss (in-iteration):\t\t0.913320\n",
      "  train accuracy:\t\t67.77 %\n",
      "  validation accuracy:\t\t68.20 %\n",
      "Epoch 9 of 60 took 24.991s\n",
      "  training loss (in-iteration):\t\t0.864114\n",
      "  train accuracy:\t\t69.42 %\n",
      "  validation accuracy:\t\t70.40 %\n",
      "Epoch 10 of 60 took 24.546s\n",
      "  training loss (in-iteration):\t\t0.813469\n",
      "  train accuracy:\t\t71.29 %\n",
      "  validation accuracy:\t\t68.60 %\n",
      "Epoch 11 of 60 took 24.500s\n",
      "  training loss (in-iteration):\t\t0.777290\n",
      "  train accuracy:\t\t72.57 %\n",
      "  validation accuracy:\t\t70.00 %\n",
      "Epoch 12 of 60 took 23.716s\n",
      "  training loss (in-iteration):\t\t0.737937\n",
      "  train accuracy:\t\t73.78 %\n",
      "  validation accuracy:\t\t71.40 %\n",
      "Epoch 13 of 60 took 24.299s\n",
      "  training loss (in-iteration):\t\t0.707438\n",
      "  train accuracy:\t\t75.00 %\n",
      "  validation accuracy:\t\t71.80 %\n",
      "Epoch 14 of 60 took 24.665s\n",
      "  training loss (in-iteration):\t\t0.670899\n",
      "  train accuracy:\t\t76.23 %\n",
      "  validation accuracy:\t\t75.00 %\n",
      "Epoch 15 of 60 took 24.834s\n",
      "  training loss (in-iteration):\t\t0.647466\n",
      "  train accuracy:\t\t77.05 %\n",
      "  validation accuracy:\t\t72.20 %\n",
      "Epoch 16 of 60 took 24.698s\n",
      "  training loss (in-iteration):\t\t0.618581\n",
      "  train accuracy:\t\t78.07 %\n",
      "  validation accuracy:\t\t72.90 %\n",
      "Epoch 17 of 60 took 24.566s\n",
      "  training loss (in-iteration):\t\t0.600174\n",
      "  train accuracy:\t\t78.83 %\n",
      "  validation accuracy:\t\t73.70 %\n",
      "Epoch 18 of 60 took 24.555s\n",
      "  training loss (in-iteration):\t\t0.572866\n",
      "  train accuracy:\t\t79.86 %\n",
      "  validation accuracy:\t\t73.00 %\n",
      "Epoch 19 of 60 took 23.975s\n",
      "  training loss (in-iteration):\t\t0.550439\n",
      "  train accuracy:\t\t80.60 %\n",
      "  validation accuracy:\t\t75.00 %\n",
      "Epoch 20 of 60 took 24.106s\n",
      "  training loss (in-iteration):\t\t0.531355\n",
      "  train accuracy:\t\t81.21 %\n",
      "  validation accuracy:\t\t74.20 %\n",
      "Epoch 21 of 60 took 24.200s\n",
      "  training loss (in-iteration):\t\t0.513089\n",
      "  train accuracy:\t\t81.73 %\n",
      "  validation accuracy:\t\t74.40 %\n",
      "Epoch 22 of 60 took 24.058s\n",
      "  training loss (in-iteration):\t\t0.492860\n",
      "  train accuracy:\t\t82.55 %\n",
      "  validation accuracy:\t\t76.30 %\n",
      "Epoch 23 of 60 took 23.666s\n",
      "  training loss (in-iteration):\t\t0.475725\n",
      "  train accuracy:\t\t83.11 %\n",
      "  validation accuracy:\t\t76.00 %\n",
      "Epoch 24 of 60 took 23.328s\n",
      "  training loss (in-iteration):\t\t0.455758\n",
      "  train accuracy:\t\t83.67 %\n",
      "  validation accuracy:\t\t76.30 %\n",
      "Epoch 25 of 60 took 23.290s\n",
      "  training loss (in-iteration):\t\t0.440040\n",
      "  train accuracy:\t\t84.32 %\n",
      "  validation accuracy:\t\t75.30 %\n",
      "Epoch 26 of 60 took 23.777s\n",
      "  training loss (in-iteration):\t\t0.428014\n",
      "  train accuracy:\t\t84.83 %\n",
      "  validation accuracy:\t\t78.40 %\n",
      "Epoch 27 of 60 took 24.107s\n",
      "  training loss (in-iteration):\t\t0.410695\n",
      "  train accuracy:\t\t85.25 %\n",
      "  validation accuracy:\t\t77.60 %\n",
      "Epoch 28 of 60 took 23.807s\n",
      "  training loss (in-iteration):\t\t0.394327\n",
      "  train accuracy:\t\t85.95 %\n",
      "  validation accuracy:\t\t78.20 %\n",
      "Epoch 29 of 60 took 23.544s\n",
      "  training loss (in-iteration):\t\t0.385624\n",
      "  train accuracy:\t\t86.29 %\n",
      "  validation accuracy:\t\t78.80 %\n",
      "Epoch 30 of 60 took 23.369s\n",
      "  training loss (in-iteration):\t\t0.370414\n",
      "  train accuracy:\t\t86.83 %\n",
      "  validation accuracy:\t\t78.40 %\n",
      "Epoch 31 of 60 took 22.939s\n",
      "  training loss (in-iteration):\t\t0.359413\n",
      "  train accuracy:\t\t87.11 %\n",
      "  validation accuracy:\t\t79.50 %\n",
      "Epoch 32 of 60 took 23.075s\n",
      "  training loss (in-iteration):\t\t0.350959\n",
      "  train accuracy:\t\t87.49 %\n",
      "  validation accuracy:\t\t79.20 %\n",
      "Epoch 33 of 60 took 23.371s\n",
      "  training loss (in-iteration):\t\t0.341615\n",
      "  train accuracy:\t\t87.98 %\n",
      "  validation accuracy:\t\t79.50 %\n",
      "Epoch 34 of 60 took 23.426s\n",
      "  training loss (in-iteration):\t\t0.322678\n",
      "  train accuracy:\t\t88.38 %\n",
      "  validation accuracy:\t\t80.20 %\n",
      "Epoch 35 of 60 took 23.394s\n",
      "  training loss (in-iteration):\t\t0.321406\n",
      "  train accuracy:\t\t88.31 %\n",
      "  validation accuracy:\t\t79.50 %\n",
      "Epoch 36 of 60 took 23.466s\n",
      "  training loss (in-iteration):\t\t0.310313\n",
      "  train accuracy:\t\t88.91 %\n",
      "  validation accuracy:\t\t81.10 %\n",
      "Epoch 37 of 60 took 23.047s\n",
      "  training loss (in-iteration):\t\t0.299873\n",
      "  train accuracy:\t\t89.44 %\n",
      "  validation accuracy:\t\t79.80 %\n",
      "Epoch 38 of 60 took 22.888s\n",
      "  training loss (in-iteration):\t\t0.289358\n",
      "  train accuracy:\t\t89.62 %\n",
      "  validation accuracy:\t\t80.40 %\n",
      "Epoch 39 of 60 took 22.837s\n",
      "  training loss (in-iteration):\t\t0.286593\n",
      "  train accuracy:\t\t89.70 %\n",
      "  validation accuracy:\t\t80.10 %\n",
      "Epoch 40 of 60 took 22.904s\n",
      "  training loss (in-iteration):\t\t0.274649\n",
      "  train accuracy:\t\t90.22 %\n",
      "  validation accuracy:\t\t79.70 %\n",
      "Epoch 41 of 60 took 22.873s\n",
      "  training loss (in-iteration):\t\t0.273123\n",
      "  train accuracy:\t\t90.13 %\n",
      "  validation accuracy:\t\t80.40 %\n",
      "Epoch 42 of 60 took 22.917s\n",
      "  training loss (in-iteration):\t\t0.263239\n",
      "  train accuracy:\t\t90.56 %\n",
      "  validation accuracy:\t\t79.00 %\n",
      "Epoch 43 of 60 took 23.205s\n",
      "  training loss (in-iteration):\t\t0.257559\n",
      "  train accuracy:\t\t90.69 %\n",
      "  validation accuracy:\t\t79.80 %\n",
      "Epoch 44 of 60 took 23.138s\n",
      "  training loss (in-iteration):\t\t0.249520\n",
      "  train accuracy:\t\t91.03 %\n",
      "  validation accuracy:\t\t81.40 %\n",
      "Epoch 45 of 60 took 23.334s\n",
      "  training loss (in-iteration):\t\t0.238806\n",
      "  train accuracy:\t\t91.44 %\n",
      "  validation accuracy:\t\t80.30 %\n",
      "Epoch 46 of 60 took 23.136s\n",
      "  training loss (in-iteration):\t\t0.234716\n",
      "  train accuracy:\t\t91.62 %\n",
      "  validation accuracy:\t\t81.20 %\n",
      "Epoch 47 of 60 took 22.846s\n",
      "  training loss (in-iteration):\t\t0.229400\n",
      "  train accuracy:\t\t91.82 %\n",
      "  validation accuracy:\t\t79.10 %\n",
      "Epoch 48 of 60 took 22.827s\n",
      "  training loss (in-iteration):\t\t0.224172\n",
      "  train accuracy:\t\t92.09 %\n",
      "  validation accuracy:\t\t80.80 %\n",
      "Epoch 49 of 60 took 22.982s\n",
      "  training loss (in-iteration):\t\t0.222371\n",
      "  train accuracy:\t\t92.03 %\n",
      "  validation accuracy:\t\t80.70 %\n",
      "Epoch 50 of 60 took 22.824s\n",
      "  training loss (in-iteration):\t\t0.216920\n",
      "  train accuracy:\t\t92.18 %\n",
      "  validation accuracy:\t\t80.10 %\n",
      "Epoch 51 of 60 took 23.069s\n",
      "  training loss (in-iteration):\t\t0.212482\n",
      "  train accuracy:\t\t92.34 %\n",
      "  validation accuracy:\t\t81.00 %\n",
      "Epoch 52 of 60 took 22.910s\n",
      "  training loss (in-iteration):\t\t0.208621\n",
      "  train accuracy:\t\t92.51 %\n",
      "  validation accuracy:\t\t80.70 %\n",
      "Epoch 53 of 60 took 22.847s\n",
      "  training loss (in-iteration):\t\t0.205832\n",
      "  train accuracy:\t\t92.60 %\n",
      "  validation accuracy:\t\t81.10 %\n",
      "Epoch 54 of 60 took 22.836s\n",
      "  training loss (in-iteration):\t\t0.203168\n",
      "  train accuracy:\t\t92.68 %\n",
      "  validation accuracy:\t\t80.80 %\n",
      "Epoch 55 of 60 took 22.897s\n",
      "  training loss (in-iteration):\t\t0.204536\n",
      "  train accuracy:\t\t92.78 %\n",
      "  validation accuracy:\t\t81.10 %\n",
      "Epoch 56 of 60 took 22.813s\n",
      "  training loss (in-iteration):\t\t0.201559\n",
      "  train accuracy:\t\t92.77 %\n",
      "  validation accuracy:\t\t80.60 %\n",
      "Epoch 57 of 60 took 22.919s\n",
      "  training loss (in-iteration):\t\t0.185343\n",
      "  train accuracy:\t\t93.37 %\n",
      "  validation accuracy:\t\t81.70 %\n",
      "Epoch 58 of 60 took 22.856s\n",
      "  training loss (in-iteration):\t\t0.185468\n",
      "  train accuracy:\t\t93.46 %\n",
      "  validation accuracy:\t\t81.20 %\n",
      "Epoch 59 of 60 took 22.835s\n",
      "  training loss (in-iteration):\t\t0.188011\n",
      "  train accuracy:\t\t93.37 %\n",
      "  validation accuracy:\t\t82.00 %\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epochs = 60 #количество проходов по данным\n",
    "\n",
    "batch_size = 50 #размер мини-батча\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train, y_train,batch_size):\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch= train_fun(inputs, targets)\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets)\n",
    "        val_batches += 1\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(\n",
    "        train_acc / train_batches * 100))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "updates_sgd = lasagne.updates.adagrad(loss_train, all_weights, learning_rate=5e-5)\n",
    "#функция, которая обучает сеть на 1 шаг и возвращащет значение функции потерь и точности\n",
    "train_fun = theano.function([input_X,target_y],[loss_train,accuracy_train],updates= updates_sgd)\n",
    "\n",
    "#функция, которая считает точность\n",
    "accuracy_fun = theano.function([input_X,target_y],accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 of 80 took 25.853s\n",
      "  training loss (in-iteration):\t\t0.810035\n",
      "  train accuracy:\t\t71.39 %\n",
      "  validation accuracy:\t\t70.50 %\n",
      "Epoch 63 of 80 took 25.678s\n",
      "  training loss (in-iteration):\t\t0.808366\n",
      "  train accuracy:\t\t71.20 %\n",
      "  validation accuracy:\t\t70.80 %\n",
      "Epoch 64 of 80 took 25.724s\n",
      "  training loss (in-iteration):\t\t0.808012\n",
      "  train accuracy:\t\t71.34 %\n",
      "  validation accuracy:\t\t70.60 %\n",
      "Epoch 65 of 80 took 25.686s\n",
      "  training loss (in-iteration):\t\t0.808071\n",
      "  train accuracy:\t\t71.00 %\n",
      "  validation accuracy:\t\t70.80 %\n",
      "Epoch 66 of 80 took 25.749s\n",
      "  training loss (in-iteration):\t\t0.805942\n",
      "  train accuracy:\t\t71.18 %\n",
      "  validation accuracy:\t\t71.10 %\n",
      "Epoch 67 of 80 took 26.124s\n",
      "  training loss (in-iteration):\t\t0.807404\n",
      "  train accuracy:\t\t71.27 %\n",
      "  validation accuracy:\t\t71.10 %\n",
      "Epoch 68 of 80 took 27.306s\n",
      "  training loss (in-iteration):\t\t0.805898\n",
      "  train accuracy:\t\t71.25 %\n",
      "  validation accuracy:\t\t71.20 %\n",
      "Epoch 69 of 80 took 27.255s\n",
      "  training loss (in-iteration):\t\t0.805928\n",
      "  train accuracy:\t\t71.20 %\n",
      "  validation accuracy:\t\t71.30 %\n",
      "Epoch 70 of 80 took 27.183s\n",
      "  training loss (in-iteration):\t\t0.809259\n",
      "  train accuracy:\t\t71.12 %\n",
      "  validation accuracy:\t\t71.70 %\n",
      "Epoch 71 of 80 took 26.136s\n",
      "  training loss (in-iteration):\t\t0.801445\n",
      "  train accuracy:\t\t71.45 %\n",
      "  validation accuracy:\t\t71.70 %\n",
      "Epoch 72 of 80 took 26.004s\n",
      "  training loss (in-iteration):\t\t0.805716\n",
      "  train accuracy:\t\t71.31 %\n",
      "  validation accuracy:\t\t71.60 %\n",
      "Epoch 73 of 80 took 26.260s\n",
      "  training loss (in-iteration):\t\t0.805882\n",
      "  train accuracy:\t\t71.19 %\n",
      "  validation accuracy:\t\t71.50 %\n",
      "Epoch 74 of 80 took 27.520s\n",
      "  training loss (in-iteration):\t\t0.805334\n",
      "  train accuracy:\t\t71.20 %\n",
      "  validation accuracy:\t\t71.50 %\n",
      "Epoch 75 of 80 took 27.432s\n",
      "  training loss (in-iteration):\t\t0.807799\n",
      "  train accuracy:\t\t70.99 %\n",
      "  validation accuracy:\t\t71.60 %\n",
      "Epoch 76 of 80 took 27.709s\n",
      "  training loss (in-iteration):\t\t0.803317\n",
      "  train accuracy:\t\t71.28 %\n",
      "  validation accuracy:\t\t71.50 %\n",
      "Epoch 77 of 80 took 26.861s\n",
      "  training loss (in-iteration):\t\t0.806781\n",
      "  train accuracy:\t\t71.36 %\n",
      "  validation accuracy:\t\t71.60 %\n",
      "Epoch 78 of 80 took 26.419s\n",
      "  training loss (in-iteration):\t\t0.805047\n",
      "  train accuracy:\t\t71.13 %\n",
      "  validation accuracy:\t\t71.60 %\n",
      "Epoch 79 of 80 took 25.965s\n",
      "  training loss (in-iteration):\t\t0.806015\n",
      "  train accuracy:\t\t71.28 %\n",
      "  validation accuracy:\t\t71.60 %\n",
      "Epoch 80 of 80 took 26.168s\n",
      "  training loss (in-iteration):\t\t0.792071\n",
      "  train accuracy:\t\t71.44 %\n",
      "  validation accuracy:\t\t71.60 %\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 80 #количество проходов по данным\n",
    "\n",
    "batch_size = 50 #размер мини-батча\n",
    "\n",
    "for epoch in range(60 , num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train, y_train,batch_size):\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch= train_fun(inputs, targets)\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets)\n",
    "        val_batches += 1\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(\n",
    "        train_acc / train_batches * 100))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t65.25 %\n",
      "Нужно больше магии!\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test, y_test, 500):\n",
    "    inputs, targets = batch\n",
    "    acc = accuracy_fun(inputs, targets)\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_acc / test_batches * 100))\n",
    "\n",
    "if test_acc / test_batches * 100 > 80:\n",
    "    print(\"Achievement unlocked: колдун 80 уровня\")\n",
    "else:\n",
    "    print(\"Нужно больше магии!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заполните форму\n",
    "\n",
    "https://goo.gl/forms/FsANPB1jSqmX1JBJ3"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
